{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6317f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id, task_id, flow_name, step_name = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca44f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, torch, IProgress\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import shutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import yaml\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from metaflow import FlowSpec, Flow, step, IncludeFile, card, Parameter\n",
    "import os.path\n",
    "from os.path import exists\n",
    "train_df = pd.read_csv('train.csv',nrows=500)\n",
    "\n",
    "train_df['image_path'] = f'../512data/train/'+(train_df).image_id+('.png')\n",
    "\n",
    "train_df = train_df[train_df.class_id!=14].reset_index(drop = True)\n",
    "\n",
    "print(\"Training on\",(train_df).image_id.nunique(),\"images\")\n",
    "\n",
    "#Pre-Processing\n",
    "train_df['x_min'] = train_df.apply(lambda row: (row.x_min)/row.width, axis =1)\n",
    "train_df['y_min'] = train_df.apply(lambda row: (row.y_min)/row.height, axis =1)\n",
    "\n",
    "train_df['x_max'] = train_df.apply(lambda row: (row.x_max)/row.width, axis =1)\n",
    "train_df['y_max'] = train_df.apply(lambda row: (row.y_max)/row.height, axis =1)\n",
    "\n",
    "train_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\n",
    "train_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n",
    "\n",
    "train_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\n",
    "train_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n",
    "\n",
    "train_df['area'] = train_df['w']*train_df['h']\n",
    "#print(train_df.head())\n",
    "\n",
    "features = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\n",
    "X = train_df[features]\n",
    "y = train_df['class_id']\n",
    "#(X).shape, (y).shape\n",
    "\n",
    "class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\n",
    "classes = list(np.array(class_names)[np.argsort(class_ids)])\n",
    "classes = list(map(lambda x: str(x), classes))\n",
    "#print(classes)\n",
    "\n",
    "train_data, val_data = model_selection.train_test_split(train_df, test_size = 0.30)\n",
    "train_df.head()\n",
    "\n",
    "train_files = []\n",
    "val_files   = []\n",
    "val_files += list(val_data.image_path.unique())\n",
    "train_files += list(train_data.image_path.unique())\n",
    "\n",
    "os.makedirs('labels/train', exist_ok = True)\n",
    "os.makedirs('labels/val', exist_ok = True)\n",
    "os.makedirs('images/train', exist_ok = True)\n",
    "os.makedirs('images/val', exist_ok = True)\n",
    "label_dir = '../labels'\n",
    "\n",
    "for file in (train_files):\n",
    "    shutil.copy(file, 'images/train')\n",
    "    filename = file.split('/')[-1].split('.')[0]\n",
    "    shutil.copy(os.path.join(label_dir, filename+'.txt'), 'labels/train')\n",
    "\n",
    "for file in (val_files):\n",
    "    shutil.copy(file, 'images/val')\n",
    "    filename = file.split('/')[-1].split('.')[0]\n",
    "    shutil.copy(os.path.join(label_dir, filename+'.txt'), 'labels/val')\n",
    "\n",
    "\n",
    "with open('./train.txt', 'w') as f:\n",
    "    for path in glob('./images/train/*'):\n",
    "        f.write(path+'\\n')\n",
    "\n",
    "with open('./val.txt', 'w') as f:\n",
    "    for path in glob('./images/val/*'):\n",
    "        f.write(path+'\\n')\n",
    "\n",
    "data = dict(\n",
    "    train =  join( '../vinbigdata/train.txt'),\n",
    "    val   =  join( '../vinbigdata/val.txt' ),\n",
    "    nc    = 14,\n",
    "    names = classes\n",
    "    )\n",
    "\n",
    "with open(join( '../yolov5', 'vinbigdata.yaml'), 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n",
    "f = open(join( '../yolov5', 'vinbigdata.yaml'), 'r')\n",
    "\n",
    "os.system('cd .. && cd yolov5 && python train.py --img 128 --batch 16 --epochs 2 --data vinbigdata.yaml --weights .weights/yolov5x.pt --cache')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
